{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"12V-qg4Aafo3brfPy1hT7GNMQKgUkFMva","authorship_tag":"ABX9TyO9gYMXUcLYA0OGTAeMEVJ3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install labml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MPjeMJpOHaoK","executionInfo":{"status":"ok","timestamp":1686885600190,"user_tz":420,"elapsed":7761,"user":{"displayName":"Shuyang Cui","userId":"09002252515431913793"}},"outputId":"75aefac5-bdbb-4699-d3c2-03d6085172c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting labml\n","  Downloading labml-0.4.162-py3-none-any.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gitpython (from labml)\n","  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from labml) (6.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from labml) (1.22.4)\n","Collecting gitdb<5,>=4.0.1 (from gitpython->labml)\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->labml)\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Installing collected packages: smmap, gitdb, gitpython, labml\n","Successfully installed gitdb-4.0.10 gitpython-3.1.31 labml-0.4.162 smmap-5.0.0\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"bYRtiIw85-MU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"h6zKBYVJHJmA"},"outputs":[],"source":["import itertools\n","import random\n","import zipfile\n","from typing import Tuple\n","\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","from PIL import Image\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision.transforms import InterpolationMode\n","from torchvision.utils import make_grid\n","import cv2\n","import os\n","import torchvision\n","from torchvision.utils import save_image\n","\n","from labml import lab, tracker, experiment, monit\n","from labml.configs import BaseConfigs\n","from labml.utils.download import download_file\n","from labml.utils.pytorch import get_modules\n","\n","class GeneratorResNet(nn.Module):\n","    \"\"\"\n","    The generator is a residual network.\n","    \"\"\"\n","\n","    def __init__(self, input_channels: int, n_residual_blocks: int):\n","        super().__init__()\n","        out_features = 64\n","        layers = [\n","            nn.Conv2d(input_channels, out_features, kernel_size=7, padding=3, padding_mode='reflect'),\n","            nn.InstanceNorm2d(out_features),\n","            nn.ReLU(inplace=True),\n","        ]\n","        in_features = out_features\n","\n","        for _ in range(2):\n","            out_features *= 2\n","            layers += [\n","                nn.Conv2d(in_features, out_features, kernel_size=3, stride=2, padding=1),\n","                nn.InstanceNorm2d(out_features),\n","                nn.ReLU(inplace=True),\n","            ]\n","            in_features = out_features\n","\n","        for _ in range(n_residual_blocks):\n","            layers += [ResidualBlock(out_features)]\n","\n","        for _ in range(2):\n","            out_features //= 2\n","            layers += [\n","                nn.Upsample(scale_factor=2),\n","                nn.Conv2d(in_features, out_features, kernel_size=3, stride=1, padding=1),\n","                nn.InstanceNorm2d(out_features),\n","                nn.ReLU(inplace=True),\n","            ]\n","            in_features = out_features\n","\n","        layers += [nn.Conv2d(out_features, input_channels, 7, padding=3, padding_mode='reflect'), nn.Tanh()]\n","\n","        self.layers = nn.Sequential(*layers)\n","\n","        self.apply(weights_init_normal)\n","\n","    def forward(self, x):\n","        return self.layers(x)\n","\n","\n","class ResidualBlock(nn.Module):\n","    \"\"\"\n","    This is the residual block, with two convolution layers.\n","    \"\"\"\n","\n","    def __init__(self, in_features: int):\n","        super().__init__()\n","        self.block = nn.Sequential(\n","            nn.Conv2d(in_features, in_features, kernel_size=3, padding=1, padding_mode='reflect'),\n","            nn.InstanceNorm2d(in_features),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_features, in_features, kernel_size=3, padding=1, padding_mode='reflect'),\n","            nn.InstanceNorm2d(in_features),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","    def forward(self, x: torch.Tensor):\n","        return x + self.block(x)\n","\n","\n","class Discriminator(nn.Module):\n","    \"\"\"\n","    This is the discriminator.\n","    \"\"\"\n","\n","    def __init__(self, input_shape: Tuple[int, int, int]):\n","        super().__init__()\n","        channels, height, width = input_shape\n","        self.output_shape = (1, height // 2 ** 4, width // 2 ** 4)\n","\n","        self.layers = nn.Sequential(\n","            DiscriminatorBlock(channels, 64, normalize=False),\n","            DiscriminatorBlock(64, 128),\n","            DiscriminatorBlock(128, 256),\n","            DiscriminatorBlock(256, 512),\n","            nn.ZeroPad2d((1, 0, 1, 0)),\n","            nn.Conv2d(512, 1, kernel_size=4, padding=1)\n","        )\n","\n","        self.apply(weights_init_normal)\n","\n","    def forward(self, img):\n","        return self.layers(img)\n","\n","\n","class DiscriminatorBlock(nn.Module):\n","    \"\"\"\n","    This is the discriminator block module.\n","    It does a convolution, an optional normalization, and a leaky ReLU.\n","\n","    It shrinks the height and width of the input feature map by half.\n","    \"\"\"\n","\n","    def __init__(self, in_filters: int, out_filters: int, normalize: bool = True):\n","        super().__init__()\n","        layers = [nn.Conv2d(in_filters, out_filters, kernel_size=4, stride=2, padding=1)]\n","        if normalize:\n","            layers.append(nn.InstanceNorm2d(out_filters))\n","        layers.append(nn.LeakyReLU(0.2, inplace=True))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x: torch.Tensor):\n","        return self.layers(x)\n","\n","\n","def weights_init_normal(m):\n","    classname = m.__class__.__name__\n","    if classname.find(\"Conv\") != -1:\n","        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n","\n","\n","def load_image(path: str):\n","    image = Image.open(path)\n","    if image.mode != 'RGB':\n","        image = Image.new(\"RGB\", image.size).paste(image)\n","\n","    return image\n","\n","\n","class ImageDataset(Dataset):\n","\n","    def __init__(self, dir_a,dir_b, transform):\n","        self.files_a = os.listdir(dir_a)\n","        self.files_b = os.listdir(dir_b)\n","        self.root_dir_a=dir_a\n","        self.root_dir_b=dir_b\n","        self.transform=transform\n","    def __getitem__(self, index):\n","        index_a=index % len(self.files_a)\n","        index_b=index % len(self.files_b)\n","        a=self.files_a[index_a]\n","        b=self.files_b[index_b]\n","        image_a=Image.open(os.path.join(self.root_dir_a,a))\n","        image_b=Image.open(os.path.join(self.root_dir_b,b))\n","        image_a=image_a.convert('RGB')\n","        image_b=image_b.convert('RGB')\n","        image_a=self.transform(image_a)\n","        image_b=self.transform(image_b)\n","        return {\"x\": image_a,\n","                \"y\": image_b}\n","\n","    def __len__(self):\n","        # Number of images in the dataset\n","        return max(len(self.files_a), len(self.files_b))\n","\n","\n","class ReplayBuffer:\n","\n","    def __init__(self, max_size: int = 50):\n","        self.max_size = max_size\n","        self.data = []\n","\n","    def push_and_pop(self, data: torch.Tensor):\n","        \"\"\"Add/retrieve an image\"\"\"\n","        data = data.detach()\n","        res = []\n","        for element in data:\n","            if len(self.data) < self.max_size:\n","                self.data.append(element)\n","                res.append(element)\n","            else:\n","                if random.uniform(0, 1) > 0.5:\n","                    i = random.randint(0, self.max_size - 1)\n","                    res.append(self.data[i].clone())\n","                    self.data[i] = element\n","                else:\n","                    res.append(element)\n","        return torch.stack(res)\n"]},{"cell_type":"code","source":["class Configs(BaseConfigs):\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    epochs: int = 200\n","    batch_size: int = 1\n","    data_loader_workers = 8\n","    learning_rate = 0.0002\n","    adam_betas = (0.5, 0.999)\n","    decay_start = 100\n","    gan_loss = torch.nn.MSELoss()\n","    cycle_loss = torch.nn.L1Loss()\n","    identity_loss = torch.nn.L1Loss()\n","    img_height = 128\n","    img_width = 128\n","    img_channels = 3\n","    n_residual_blocks = 9\n","    cyclic_loss_coefficient = 10.0\n","    identity_loss_coefficient = 5.\n","    sample_interval = 20\n","\n","    generator_xy: GeneratorResNet\n","    generator_yx: GeneratorResNet\n","    discriminator_x: Discriminator\n","    discriminator_y: Discriminator\n","\n","    # Optimizers\n","    generator_optimizer: torch.optim.Adam\n","    discriminator_optimizer: torch.optim.Adam\n","\n","    # Learning rate schedules\n","    generator_lr_scheduler: torch.optim.lr_scheduler.LambdaLR\n","    discriminator_lr_scheduler: torch.optim.lr_scheduler.LambdaLR\n","\n","    # Data loaders\n","    dataloader: DataLoader\n","    valid_dataloader: DataLoader\n","\n","    def sample_images(self, n: int):\n","        batch = next(iter(self.dataloader))\n","        self.generator_xy.eval()\n","        self.generator_yx.eval()\n","        with torch.no_grad():\n","            data_x, data_y = batch['x'].to(self.device), batch['y'].to(self.device)\n","            noise_x=torch.randn_like(data_x)\n","            noise_y=torch.rand_like(data_y)\n","            gen_y = self.generator_xy(data_x)\n","            gen_x = self.generator_yx(data_y)\n","            gen_y_noise=self.generator_xy(noise_x)\n","            gen_x_noise=self.generator_yx(noise_y)\n","\n","            data_x = make_grid(data_x, nrow=4, normalize=True)\n","            data_y = make_grid(data_y, nrow=4, normalize=True)\n","            gen_x = make_grid(gen_x, nrow=4, normalize=True)\n","            gen_y = make_grid(gen_y, nrow=4, normalize=True)\n","            gen_x_noise = make_grid(gen_x_noise, nrow=4, normalize=True)\n","            gen_y_noise = make_grid(gen_y_noise, nrow=4, normalize=True)\n","\n","            image_grid = torch.cat((data_x, gen_y, data_y, gen_x,gen_x_noise,gen_y_noise), 1)\n","\n","        plot_image(image_grid)\n","        save_image(image_grid,f'/content/drive/Shareddrives/ECE285/CycleGAN/results/{n}.png')\n","\n","    def initialize(self):\n","        input_shape = (self.img_channels, self.img_height, self.img_width)\n","\n","        self.generator_xy = GeneratorResNet(self.img_channels, self.n_residual_blocks).to(self.device)\n","        self.generator_yx = GeneratorResNet(self.img_channels, self.n_residual_blocks).to(self.device)\n","        self.discriminator_x = Discriminator(input_shape).to(self.device)\n","        self.discriminator_y = Discriminator(input_shape).to(self.device)\n","\n","        pth_name=os.listdir('/content/drive/Shareddrives/ECE285/CycleGAN/checkpoints')\n","        if len(os.listdir('/content/drive/Shareddrives/ECE285/CycleGAN/checkpoints'))!=0:\n","            checkpoint = torch.load('/content/drive/Shareddrives/ECE285/CycleGAN/checkpoints/'+pth_name[0], map_location='cpu')\n","            self.generator_xy.load_state_dict(checkpoint['generator_xy'])\n","            self.generator_yx.load_state_dict(checkpoint['generator_yx'])\n","            self.discriminator_x.load_state_dict(checkpoint['discriminator_x'])\n","            self.discriminator_y.load_state_dict(checkpoint['discriminator_y'])\n","\n","        self.generator_optimizer = torch.optim.Adam(\n","            itertools.chain(self.generator_xy.parameters(), self.generator_yx.parameters()),\n","            lr=self.learning_rate, betas=self.adam_betas)\n","        self.discriminator_optimizer = torch.optim.Adam(\n","            itertools.chain(self.discriminator_x.parameters(), self.discriminator_y.parameters()),\n","            lr=self.learning_rate, betas=self.adam_betas)\n","\n","        decay_epochs = self.epochs - self.decay_start\n","        self.generator_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(\n","            self.generator_optimizer, lr_lambda=lambda e: 1.0 - max(0, e - self.decay_start) / decay_epochs)\n","        self.discriminator_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(\n","            self.discriminator_optimizer, lr_lambda=lambda e: 1.0 - max(0, e - self.decay_start) / decay_epochs)\n","\n","        transforms_ = torchvision.transforms.Compose([\n","            transforms.Resize(int(self.img_height * 1.12), InterpolationMode.BICUBIC),\n","            transforms.RandomCrop((self.img_height, self.img_width)),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","        ])\n","\n","        self.dataloader = DataLoader(\n","            ImageDataset('/content/drive/Shareddrives/ECE285/vtuber_image/vtuber_images','/content/drive/MyDrive/ECE285SPRING/animegirl-faces/size256', transforms_),\n","            batch_size=self.batch_size,\n","            shuffle=True,\n","            num_workers=self.data_loader_workers,\n","        )\n","\n","    def run(self):\n","        gen_x_buffer = ReplayBuffer()\n","        gen_y_buffer = ReplayBuffer()\n","\n","        for epoch in monit.loop(self.epochs):\n","            for i, batch in monit.enum('Train', self.dataloader):\n","                data_x, data_y = batch['x'].to(self.device), batch['y'].to(self.device)\n","                true_labels = torch.ones(data_x.size(0), *self.discriminator_x.output_shape,\n","                                         device=self.device, requires_grad=False)\n","                false_labels = torch.zeros(data_x.size(0), *self.discriminator_x.output_shape,\n","                                           device=self.device, requires_grad=False)\n","                gen_x, gen_y,loss_generator,loss_cycle,loss_gan,loss_identity = self.optimize_generators(data_x, data_y, true_labels)\n","\n","                #  Train discriminators\n","                loss_discriminator=self.optimize_discriminator(data_x, data_y,\n","                                            gen_x_buffer.push_and_pop(gen_x), gen_y_buffer.push_and_pop(gen_y),\n","                                            true_labels, false_labels)\n","                tracker.save()\n","                tracker.add_global_step(max(len(data_x), len(data_y)))\n","\n","                batches_done = epoch * len(self.dataloader) + i\n","                if batches_done % self.sample_interval == 0:\n","                    # Sample images\n","                    if len(os.listdir('/content/drive/Shareddrives/ECE285/CycleGAN/checkpoints'))!=0:\n","                        batches=int(os.listdir('/content/drive/Shareddrives/ECE285/CycleGAN/checkpoints/')[0].split(\".\")[0].split(\"_\")[1])\n","                        batches+=self.sample_interval\n","                    else:\n","                      batches=batches_done\n","                    self.sample_images(batches)\n","\n","                    pth_name=os.listdir('/content/drive/Shareddrives/ECE285/CycleGAN/checkpoints')\n","                    if len(os.listdir('/content/drive/Shareddrives/ECE285/CycleGAN/checkpoints'))!=0:\n","                        checkpoint = torch.load('/content/drive/Shareddrives/ECE285/CycleGAN/checkpoints/'+pth_name[0], map_location='cpu')\n","                        loss_generator_result=checkpoint[\"loss_generator_result\"]\n","                        loss_generator_result.append(loss_generator)\n","                        loss_cycle_result=checkpoint[\"loss_cycle_result\"]\n","                        loss_cycle_result.append(loss_cycle)\n","                        loss_gan_result=checkpoint[\"loss_gan_result\"]\n","                        loss_gan_result.append(loss_gan)\n","                        loss_identity_result=checkpoint[\"loss_identity_result\"]\n","                        loss_identity_result.append(loss_identity)\n","                        loss_discriminator_result=checkpoint[\"loss_discriminator_result\"]\n","                        loss_discriminator_result.append(loss_discriminator)\n","                        os.remove('/content/drive/Shareddrives/ECE285/CycleGAN/checkpoints/'+pth_name[0])\n","                    else:\n","                        loss_generator_result=[]\n","                        loss_cycle_result=[]\n","                        loss_gan_result=[]\n","                        loss_identity_result=[]\n","                        loss_discriminator_result=[]\n","\n","                        loss_generator_result.append(loss_generator)\n","                        loss_cycle_result.append(loss_cycle)\n","                        loss_gan_result.append(loss_gan)\n","                        loss_identity_result.append(loss_identity)\n","                        loss_discriminator_result.append(loss_discriminator)\n","\n","                    torch.save({\"generator_xy\":self.generator_xy.state_dict(),\n","                                \"generator_yx\":self.generator_yx.state_dict(),\n","                                \"discriminator_x\":self.discriminator_x.state_dict(),\n","                                \"discriminator_y\":self.discriminator_y.state_dict(),\n","                                \"loss_generator_result\":loss_generator_result,\n","                                \"loss_cycle_result\":loss_cycle_result,\n","                                \"loss_gan_result\":loss_gan_result,\n","                                \"loss_identity_result\":loss_identity_result,\n","                                \"loss_discriminator_result\":loss_discriminator_result},f'/content/drive/Shareddrives/ECE285/CycleGAN/checkpoints/trained_{batches}.pth')\n","\n","            # Update learning rates\n","            self.generator_lr_scheduler.step()\n","            self.discriminator_lr_scheduler.step()\n","            tracker.new_line()\n","\n","    def optimize_generators(self, data_x: torch.Tensor, data_y: torch.Tensor, true_labels: torch.Tensor):\n","        self.generator_xy.train()\n","        self.generator_yx.train()\n","        loss_identity = (self.identity_loss(self.generator_yx(data_x), data_x) +\n","                         self.identity_loss(self.generator_xy(data_y), data_y))\n","        gen_y = self.generator_xy(data_x)\n","        gen_x = self.generator_yx(data_y)\n","\n","        loss_gan = (self.gan_loss(self.discriminator_y(gen_y), true_labels) +\n","                    self.gan_loss(self.discriminator_x(gen_x), true_labels))\n","\n","        loss_cycle = (self.cycle_loss(self.generator_yx(gen_y), data_x) +\n","                      self.cycle_loss(self.generator_xy(gen_x), data_y))\n","\n","        # Total loss\n","        loss_generator = (loss_gan +\n","                          self.cyclic_loss_coefficient * loss_cycle +\n","                          self.identity_loss_coefficient * loss_identity)\n","\n","        self.generator_optimizer.zero_grad()\n","        loss_generator.backward()\n","        self.generator_optimizer.step()\n","\n","        # Log losses\n","        tracker.add({'loss.generator': loss_generator,\n","                     'loss.generator.cycle': loss_cycle,\n","                     'loss.generator.gan': loss_gan,\n","                     'loss.generator.identity': loss_identity})\n","\n","        return gen_x, gen_y,loss_generator.detach().cpu().item(),loss_cycle.detach().cpu().item(),loss_gan.detach().cpu().item(),loss_identity.detach().cpu().item()\n","\n","    def optimize_discriminator(self, data_x: torch.Tensor, data_y: torch.Tensor,\n","                               gen_x: torch.Tensor, gen_y: torch.Tensor,\n","                               true_labels: torch.Tensor, false_labels: torch.Tensor):\n","\n","        loss_discriminator = (self.gan_loss(self.discriminator_x(data_x), true_labels) +\n","                              self.gan_loss(self.discriminator_x(gen_x), false_labels) +\n","                              self.gan_loss(self.discriminator_y(data_y), true_labels) +\n","                              self.gan_loss(self.discriminator_y(gen_y), false_labels))\n","\n","        self.discriminator_optimizer.zero_grad()\n","        loss_discriminator.backward()\n","        self.discriminator_optimizer.step()\n","\n","        # Log losses\n","        tracker.add({'loss.discriminator': loss_discriminator})\n","        return loss_discriminator.detach().cpu().item()\n","\n","def train():\n","    conf = Configs()\n","    conf.initialize()\n","    conf.run()\n","\n","\n","def plot_image(img: torch.Tensor):\n","    from matplotlib import pyplot as plt\n","    img = img.cpu()\n","    img_min, img_max = img.min(), img.max()\n","    img = (img - img_min) / (img_max - img_min + 1e-5)\n","    img = img.permute(1, 2, 0)\n","    plt.imshow(img)\n","    plt.axis('off')\n","    plt.show()\n","\n","\n","def evaluate():\n","    conf = Configs()\n","    conf.initialize()\n","\n","    transforms_ = [\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","    ]\n","    '''\n","    #dataset = ImageDataset('/content/drive/Shareddrives/ECE285/vtuber_image/vtuber_images','/content/drive/MyDrive/ECE285SPRING/animegirl-faces/size256', transforms)\n","\n","    # Get an image from dataset\n","    x_image = dataset[10]['x']\n","    y_image = dataset[10]['y']\n","    # Display the image\n","    plot_image(x_image)\n","    plot_image(y_image)\n","    '''\n","    conf.generator_xy.eval()\n","    conf.generator_yx.eval()\n","    if not os.path.exists('/content/drive/Shareddrives/ECE285/CycleGAN/images_for_evaluation/real_vtuber'):\n","        os.makedirs('/content/drive/Shareddrives/ECE285/CycleGAN/images_for_evaluation/real_vtuber')\n","    if not os.path.exists('/content/drive/Shareddrives/ECE285/CycleGAN/images_for_evaluation/real_faces'):\n","        os.makedirs('/content/drive/Shareddrives/ECE285/CycleGAN/images_for_evaluation/real_faces')\n","    if not os.path.exists('/content/drive/Shareddrives/ECE285/CycleGAN/images_for_evaluation/fake_faces'):\n","        os.makedirs('/content/drive/Shareddrives/ECE285/CycleGAN/images_for_evaluation/fake_faces')\n","    if not os.path.exists('/content/drive/Shareddrives/ECE285/CycleGAN/images_for_evaluation/fake_vtuber'):\n","        os.makedirs('/content/drive/Shareddrives/ECE285/CycleGAN/images_for_evaluation/fake_vtuber')\n","    with torch.no_grad():\n","        for idx,batch in enumerate(conf.dataloader):\n","            x_image,y_image=batch['x'],batch['y']\n","            data_x = x_image.to(conf.device)\n","            data_y = y_image.to(conf.device)\n","            generated_y = conf.generator_xy(data_x)\n","            generated_x = conf.generator_yx(data_y)\n","            save_image(x_image,f'/content/drive/Shareddrives/ECE285/CycleGAN/images_for_evaluation/real_vtuber/{idx}.png')\n","            save_image(y_image,f'/content/drive/Shareddrives/ECE285/CycleGAN/images_for_evaluation/real_faces/{idx}.png')\n","            save_image(generated_y,f'/content/drive/Shareddrives/ECE285/CycleGAN/images_for_evaluation/fake_faces/{idx}.png')\n","            save_image(generated_x,f'/content/drive/Shareddrives/ECE285/CycleGAN/images_for_evaluation/fake_vtuber/{idx}.png')\n","\n","    '''\n","    # Display the generated image.\n","    plot_image(generated_y[0].cpu())\n","    plot_image(generated_x[0].cpu())\n","    '''"],"metadata":{"id":"h-Shl0O_I0Ur"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train()"],"metadata":{"id":"3o76HvM8LNr5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_i3hIFxNocn0","executionInfo":{"status":"ok","timestamp":1686884730880,"user_tz":420,"elapsed":8026,"user":{"displayName":"Shuyang Cui","userId":"09002252515431913793"}},"outputId":"7d649328-4aed-4b52-e646-69a1d0f22fcd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","import torch\n","import matplotlib.pyplot as plt\n","\n","pth_name=os.listdir('/content/drive/Shareddrives/ECE285/CycleGAN/checkpoints')\n","checkpoint = torch.load('/content/drive/Shareddrives/ECE285/CycleGAN/checkpoints/'+pth_name[0], map_location='cpu')\n","loss_generator_result=checkpoint[\"loss_generator_result\"]\n","loss_cycle_result=checkpoint[\"loss_cycle_result\"]\n","loss_gan_result=checkpoint[\"loss_gan_result\"]\n","loss_identity_result=checkpoint[\"loss_identity_result\"]\n","loss_discriminator_result=checkpoint[\"loss_discriminator_result\"]\n","\n","num_epochs = len(loss_generator_result)\n","epochs = range(1, num_epochs + 1)\n","\n","plt.plot(epochs, loss_generator_result, label='Generator Loss')\n","plt.plot(epochs, loss_cycle_result, label='Cycle Loss')\n","plt.plot(epochs, loss_gan_result, label='GAN Loss')\n","plt.plot(epochs, loss_identity_result, label='Identity Loss')\n","plt.plot(epochs, loss_discriminator_result, label='Discriminator Loss')\n","\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title('Loss Curves')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"1u-NTz9-koxd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluate()"],"metadata":{"id":"XcwelBf9sWYT"},"execution_count":null,"outputs":[]}]}